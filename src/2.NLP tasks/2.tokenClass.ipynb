{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca663b20",
   "metadata": {},
   "source": [
    "# 实体识别\n",
    "\n",
    "实体是指识别文本中具有特定意义的名词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "\n",
    "from datasets import DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments, DataCollatorForTokenClassification, BertForSequenceClassification, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e60a8d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict.load_from_disk(\"../../datas/ner_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3608fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = dataset[\"train\"].features[\"ner_tags\"].feature.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2a98b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0', 'tokens': ['海', '钓', '比', '赛', '地', '点', '在', '厦', '门', '与', '金', '门', '之', '间', '的', '海', '域', '。'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 5, 6, 0, 5, 6, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c18eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"models/macbert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "721c7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(examples):\n",
    "    tokenized_data = tokenizer(\n",
    "        examples[\"tokens\"], \n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word2ids = tokenized_data.word_ids(batch_index=idx) # words方法也ok, 返回token对应的word的索引\n",
    "        each_sentence_labels = []\n",
    "        for item in word2ids:\n",
    "            if item is None: # [CLS] and [SEP] 返回None\n",
    "                each_sentence_labels.append(-100)\n",
    "            else:\n",
    "                each_sentence_labels.append(label[item])\n",
    "        labels.append(each_sentence_labels)\n",
    "    \n",
    "    tokenized_data[\"labels\"] = labels\n",
    "    return tokenized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efa5e8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49aba28cfdb24015973d45a080a75d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20865 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f252f53af26d4e7497ac932ec91ae0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5890355f4e0144058cd89630c44a4e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4637 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_data = dataset.map(process_func, batched=True, remove_columns=dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55080e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at models/macbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"models/macbert-base\", num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedc7622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "\n",
    "    # 将标签index转化为标签名\n",
    "    predictions = [\n",
    "        [label_list[p] for p, l in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    labels = [\n",
    "        [label_list[l] for l in label if l != -100]\n",
    "        for label in labels\n",
    "    ]\n",
    "\n",
    "    return seqeval.compute(\n",
    "        predictions=predictions,\n",
    "        references=labels,\n",
    "        mode=\"strict\",\n",
    "        scheme=\"IOB2\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb97ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"trained/model_for_tokenClass\",\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=8,\n",
    "    gradient_checkpointing=True,\n",
    "    optim=\"adafactor\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_eval_batch_size=32,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_steps=200,\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"overall_f1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bb828244",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    args=args,\n",
    "    model=model,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorForTokenClassification(tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22f18b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='653' max='653' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [653/653 23:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Loc</th>\n",
       "      <th>Org</th>\n",
       "      <th>Per</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.034849</td>\n",
       "      <td>{'precision': 0.8852504897844948, 'recall': 0.9131062355658198, 'f1': 0.8989626261190848, 'number': 3464}</td>\n",
       "      <td>{'precision': 0.8043571123451516, 'recall': 0.8693444136657433, 'f1': 0.8355890836476593, 'number': 2166}</td>\n",
       "      <td>{'precision': 0.9740698985343855, 'recall': 0.9494505494505494, 'f1': 0.9616026711185309, 'number': 1820}</td>\n",
       "      <td>0.881113</td>\n",
       "      <td>0.909262</td>\n",
       "      <td>0.894966</td>\n",
       "      <td>0.989373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.026104</td>\n",
       "      <td>{'precision': 0.9058531198233021, 'recall': 0.9471709006928406, 'f1': 0.9260513688964155, 'number': 3464}</td>\n",
       "      <td>{'precision': 0.8441901408450704, 'recall': 0.8855032317636196, 'f1': 0.8643533123028391, 'number': 2166}</td>\n",
       "      <td>{'precision': 0.9736842105263158, 'recall': 0.9758241758241758, 'f1': 0.9747530186608122, 'number': 1820}</td>\n",
       "      <td>0.903732</td>\n",
       "      <td>0.936242</td>\n",
       "      <td>0.919699</td>\n",
       "      <td>0.991694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.022837</td>\n",
       "      <td>{'precision': 0.9222565253999438, 'recall': 0.9486143187066974, 'f1': 0.9352497509605805, 'number': 3464}</td>\n",
       "      <td>{'precision': 0.8521383075523203, 'recall': 0.8647276084949215, 'f1': 0.8583868010999083, 'number': 2166}</td>\n",
       "      <td>{'precision': 0.9740761169332598, 'recall': 0.9703296703296703, 'f1': 0.9721992843380126, 'number': 1820}</td>\n",
       "      <td>0.914312</td>\n",
       "      <td>0.929530</td>\n",
       "      <td>0.921858</td>\n",
       "      <td>0.992682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.8852504897844948, 'recall': 0.9131062355658198, 'f1': 0.8989626261190848, 'number': 3464}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8043571123451516, 'recall': 0.8693444136657433, 'f1': 0.8355890836476593, 'number': 2166}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9740698985343855, 'recall': 0.9494505494505494, 'f1': 0.9616026711185309, 'number': 1820}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9058531198233021, 'recall': 0.9471709006928406, 'f1': 0.9260513688964155, 'number': 3464}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8441901408450704, 'recall': 0.8855032317636196, 'f1': 0.8643533123028391, 'number': 2166}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9736842105263158, 'recall': 0.9758241758241758, 'f1': 0.9747530186608122, 'number': 1820}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9222565253999438, 'recall': 0.9486143187066974, 'f1': 0.9352497509605805, 'number': 3464}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8521383075523203, 'recall': 0.8647276084949215, 'f1': 0.8583868010999083, 'number': 2166}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9740761169332598, 'recall': 0.9703296703296703, 'f1': 0.9721992843380126, 'number': 1820}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=653, training_loss=0.049839773402188495, metrics={'train_runtime': 1430.4732, 'train_samples_per_second': 14.586, 'train_steps_per_second': 0.456, 'total_flos': 1363050820834560.0, 'train_loss': 0.049839773402188495, 'epoch': 1.0})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7dddd0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='73' max='73' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [73/73 00:31]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"{'precision': 0.9409166206515737, 'recall': 0.9471928849360756, 'f1': 0.9440443213296399, 'number': 1799}\" of type <class 'dict'> for key \"eval/LOC\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.8774062816616008, 'recall': 0.8872950819672131, 'f1': 0.8823229750382069, 'number': 976}\" of type <class 'dict'> for key \"eval/ORG\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.9748283752860412, 'recall': 0.9659863945578231, 'f1': 0.970387243735763, 'number': 882}\" of type <class 'dict'> for key \"eval/PER\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.019259439781308174,\n",
       " 'eval_LOC': {'precision': 0.9409166206515737,\n",
       "  'recall': 0.9471928849360756,\n",
       "  'f1': 0.9440443213296399,\n",
       "  'number': 1799},\n",
       " 'eval_ORG': {'precision': 0.8774062816616008,\n",
       "  'recall': 0.8872950819672131,\n",
       "  'f1': 0.8823229750382069,\n",
       "  'number': 976},\n",
       " 'eval_PER': {'precision': 0.9748283752860412,\n",
       "  'recall': 0.9659863945578231,\n",
       "  'f1': 0.970387243735763,\n",
       "  'number': 882},\n",
       " 'eval_overall_precision': 0.931917211328976,\n",
       " 'eval_overall_recall': 0.9357396773311457,\n",
       " 'eval_overall_f1': 0.9338245326784008,\n",
       " 'eval_overall_accuracy': 0.9938909730473099,\n",
       " 'eval_runtime': 33.9168,\n",
       " 'eval_samples_per_second': 68.373,\n",
       " 'eval_steps_per_second': 2.152,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(eval_dataset=tokenized_data[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe0e9c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a34a68ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label = {idx: label for idx, label in enumerate(label_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ebc82c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"token-classification\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b236d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.59083873,\n",
       "  'index': 1,\n",
       "  'word': '小',\n",
       "  'start': 0,\n",
       "  'end': 1},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.73853093,\n",
       "  'index': 2,\n",
       "  'word': '明',\n",
       "  'start': 1,\n",
       "  'end': 2},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.9979704,\n",
       "  'index': 4,\n",
       "  'word': '北',\n",
       "  'start': 3,\n",
       "  'end': 4},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9978807,\n",
       "  'index': 5,\n",
       "  'word': '京',\n",
       "  'start': 4,\n",
       "  'end': 5}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pipe(\"小明在北京上班\")\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e142d92a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
