{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4df6c92",
   "metadata": {},
   "source": [
    "# IA3\n",
    "\n",
    "对K, V, FFN进行缩放，学习对应缩放因子，理解为放大关键特征，抑制噪声"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05f041c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Collecting peft\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/6a/7b/d10c594d1afd828a0b359bb860965e261e840764fe2672d14a647f5889ee/peft-0.16.0-py3-none-any.whl (472 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/miniconda3/lib/python3.12/site-packages (from peft) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/miniconda3/lib/python3.12/site-packages (from peft) (23.2)\n",
      "Requirement already satisfied: psutil in /root/miniconda3/lib/python3.12/site-packages (from peft) (6.1.0)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/lib/python3.12/site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /root/miniconda3/lib/python3.12/site-packages (from peft) (2.7.1+cu118)\n",
      "Requirement already satisfied: transformers in /root/miniconda3/lib/python3.12/site-packages (from peft) (4.53.2)\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.12/site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /root/miniconda3/lib/python3.12/site-packages (from peft) (1.8.1)\n",
      "Requirement already satisfied: safetensors in /root/miniconda3/lib/python3.12/site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /root/miniconda3/lib/python3.12/site-packages (from peft) (0.33.4)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/miniconda3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2024.10.0)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/miniconda3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /root/miniconda3/lib/python3.12/site-packages (from huggingface_hub>=0.25.0->peft) (1.1.5)\n",
      "Requirement already satisfied: setuptools in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (69.5.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.13.3)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /root/miniconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/miniconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /root/miniconda3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.12/site-packages (from requests->huggingface_hub>=0.25.0->peft) (2024.2.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/miniconda3/lib/python3.12/site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/miniconda3/lib/python3.12/site-packages (from transformers->peft) (0.21.2)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.16.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eca0c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9057e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk(\"../../datas/alpaca_data_zh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d04d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"../../models/bloom-1b4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1789eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_func(example):\n",
    "    MAX_LENGTH = 512\n",
    "\n",
    "    instruction = \"\\n\".join([\"Human: \" + example[\"instruction\"], example[\"input\"]]).strip() + \"\\n\\nAssistant: \"\n",
    "    inputs = tokenizer(instruction)\n",
    "    response = tokenizer(example[\"output\"])\n",
    "    input_ids = inputs[\"input_ids\"] + response[\"input_ids\"] + [tokenizer.eos_token_id]\n",
    "    attention_mask = inputs[\"attention_mask\"] + response[\"attention_mask\"] + [1]\n",
    "    labels = [-100] * len(inputs[\"input_ids\"]) + response[\"input_ids\"] + [tokenizer.eos_token_id]\n",
    "\n",
    "    if len(input_ids) > MAX_LENGTH:\n",
    "        input_ids = input_ids[:MAX_LENGTH]\n",
    "        attention_mask = attention_mask[:MAX_LENGTH]\n",
    "        labels = labels[:MAX_LENGTH]\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": attention_mask,\n",
    "        \"labels\": labels,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c40034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_data = dataset.map(process_func, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6faee071",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"../../models/bloom-1b4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1805cb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.word_embeddings.weight torch.float32\n",
      "transformer.word_embeddings_layernorm.weight torch.float32\n",
      "transformer.word_embeddings_layernorm.bias torch.float32\n",
      "transformer.h.0.input_layernorm.weight torch.float32\n",
      "transformer.h.0.input_layernorm.bias torch.float32\n",
      "transformer.h.0.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.0.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.0.self_attention.dense.weight torch.float32\n",
      "transformer.h.0.self_attention.dense.bias torch.float32\n",
      "transformer.h.0.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.0.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.0.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.0.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.0.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.0.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.1.input_layernorm.weight torch.float32\n",
      "transformer.h.1.input_layernorm.bias torch.float32\n",
      "transformer.h.1.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.1.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.1.self_attention.dense.weight torch.float32\n",
      "transformer.h.1.self_attention.dense.bias torch.float32\n",
      "transformer.h.1.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.1.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.1.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.1.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.1.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.1.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.2.input_layernorm.weight torch.float32\n",
      "transformer.h.2.input_layernorm.bias torch.float32\n",
      "transformer.h.2.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.2.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.2.self_attention.dense.weight torch.float32\n",
      "transformer.h.2.self_attention.dense.bias torch.float32\n",
      "transformer.h.2.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.2.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.2.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.2.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.2.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.2.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.3.input_layernorm.weight torch.float32\n",
      "transformer.h.3.input_layernorm.bias torch.float32\n",
      "transformer.h.3.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.3.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.3.self_attention.dense.weight torch.float32\n",
      "transformer.h.3.self_attention.dense.bias torch.float32\n",
      "transformer.h.3.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.3.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.3.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.3.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.3.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.3.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.4.input_layernorm.weight torch.float32\n",
      "transformer.h.4.input_layernorm.bias torch.float32\n",
      "transformer.h.4.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.4.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.4.self_attention.dense.weight torch.float32\n",
      "transformer.h.4.self_attention.dense.bias torch.float32\n",
      "transformer.h.4.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.4.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.4.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.4.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.4.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.4.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.5.input_layernorm.weight torch.float32\n",
      "transformer.h.5.input_layernorm.bias torch.float32\n",
      "transformer.h.5.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.5.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.5.self_attention.dense.weight torch.float32\n",
      "transformer.h.5.self_attention.dense.bias torch.float32\n",
      "transformer.h.5.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.5.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.5.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.5.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.5.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.5.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.6.input_layernorm.weight torch.float32\n",
      "transformer.h.6.input_layernorm.bias torch.float32\n",
      "transformer.h.6.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.6.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.6.self_attention.dense.weight torch.float32\n",
      "transformer.h.6.self_attention.dense.bias torch.float32\n",
      "transformer.h.6.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.6.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.6.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.6.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.6.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.6.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.7.input_layernorm.weight torch.float32\n",
      "transformer.h.7.input_layernorm.bias torch.float32\n",
      "transformer.h.7.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.7.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.7.self_attention.dense.weight torch.float32\n",
      "transformer.h.7.self_attention.dense.bias torch.float32\n",
      "transformer.h.7.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.7.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.7.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.7.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.7.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.7.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.8.input_layernorm.weight torch.float32\n",
      "transformer.h.8.input_layernorm.bias torch.float32\n",
      "transformer.h.8.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.8.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.8.self_attention.dense.weight torch.float32\n",
      "transformer.h.8.self_attention.dense.bias torch.float32\n",
      "transformer.h.8.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.8.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.8.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.8.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.8.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.8.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.9.input_layernorm.weight torch.float32\n",
      "transformer.h.9.input_layernorm.bias torch.float32\n",
      "transformer.h.9.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.9.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.9.self_attention.dense.weight torch.float32\n",
      "transformer.h.9.self_attention.dense.bias torch.float32\n",
      "transformer.h.9.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.9.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.9.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.9.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.9.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.9.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.10.input_layernorm.weight torch.float32\n",
      "transformer.h.10.input_layernorm.bias torch.float32\n",
      "transformer.h.10.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.10.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.10.self_attention.dense.weight torch.float32\n",
      "transformer.h.10.self_attention.dense.bias torch.float32\n",
      "transformer.h.10.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.10.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.10.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.10.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.10.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.10.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.11.input_layernorm.weight torch.float32\n",
      "transformer.h.11.input_layernorm.bias torch.float32\n",
      "transformer.h.11.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.11.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.11.self_attention.dense.weight torch.float32\n",
      "transformer.h.11.self_attention.dense.bias torch.float32\n",
      "transformer.h.11.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.11.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.11.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.11.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.11.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.11.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.12.input_layernorm.weight torch.float32\n",
      "transformer.h.12.input_layernorm.bias torch.float32\n",
      "transformer.h.12.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.12.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.12.self_attention.dense.weight torch.float32\n",
      "transformer.h.12.self_attention.dense.bias torch.float32\n",
      "transformer.h.12.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.12.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.12.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.12.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.12.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.12.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.13.input_layernorm.weight torch.float32\n",
      "transformer.h.13.input_layernorm.bias torch.float32\n",
      "transformer.h.13.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.13.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.13.self_attention.dense.weight torch.float32\n",
      "transformer.h.13.self_attention.dense.bias torch.float32\n",
      "transformer.h.13.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.13.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.13.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.13.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.13.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.13.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.14.input_layernorm.weight torch.float32\n",
      "transformer.h.14.input_layernorm.bias torch.float32\n",
      "transformer.h.14.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.14.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.14.self_attention.dense.weight torch.float32\n",
      "transformer.h.14.self_attention.dense.bias torch.float32\n",
      "transformer.h.14.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.14.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.14.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.14.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.14.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.14.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.15.input_layernorm.weight torch.float32\n",
      "transformer.h.15.input_layernorm.bias torch.float32\n",
      "transformer.h.15.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.15.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.15.self_attention.dense.weight torch.float32\n",
      "transformer.h.15.self_attention.dense.bias torch.float32\n",
      "transformer.h.15.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.15.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.15.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.15.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.15.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.15.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.16.input_layernorm.weight torch.float32\n",
      "transformer.h.16.input_layernorm.bias torch.float32\n",
      "transformer.h.16.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.16.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.16.self_attention.dense.weight torch.float32\n",
      "transformer.h.16.self_attention.dense.bias torch.float32\n",
      "transformer.h.16.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.16.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.16.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.16.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.16.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.16.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.17.input_layernorm.weight torch.float32\n",
      "transformer.h.17.input_layernorm.bias torch.float32\n",
      "transformer.h.17.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.17.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.17.self_attention.dense.weight torch.float32\n",
      "transformer.h.17.self_attention.dense.bias torch.float32\n",
      "transformer.h.17.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.17.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.17.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.17.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.17.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.17.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.18.input_layernorm.weight torch.float32\n",
      "transformer.h.18.input_layernorm.bias torch.float32\n",
      "transformer.h.18.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.18.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.18.self_attention.dense.weight torch.float32\n",
      "transformer.h.18.self_attention.dense.bias torch.float32\n",
      "transformer.h.18.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.18.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.18.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.18.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.18.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.18.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.19.input_layernorm.weight torch.float32\n",
      "transformer.h.19.input_layernorm.bias torch.float32\n",
      "transformer.h.19.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.19.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.19.self_attention.dense.weight torch.float32\n",
      "transformer.h.19.self_attention.dense.bias torch.float32\n",
      "transformer.h.19.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.19.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.19.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.19.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.19.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.19.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.20.input_layernorm.weight torch.float32\n",
      "transformer.h.20.input_layernorm.bias torch.float32\n",
      "transformer.h.20.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.20.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.20.self_attention.dense.weight torch.float32\n",
      "transformer.h.20.self_attention.dense.bias torch.float32\n",
      "transformer.h.20.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.20.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.20.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.20.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.20.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.20.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.21.input_layernorm.weight torch.float32\n",
      "transformer.h.21.input_layernorm.bias torch.float32\n",
      "transformer.h.21.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.21.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.21.self_attention.dense.weight torch.float32\n",
      "transformer.h.21.self_attention.dense.bias torch.float32\n",
      "transformer.h.21.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.21.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.21.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.21.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.21.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.21.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.22.input_layernorm.weight torch.float32\n",
      "transformer.h.22.input_layernorm.bias torch.float32\n",
      "transformer.h.22.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.22.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.22.self_attention.dense.weight torch.float32\n",
      "transformer.h.22.self_attention.dense.bias torch.float32\n",
      "transformer.h.22.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.22.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.22.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.22.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.22.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.22.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.h.23.input_layernorm.weight torch.float32\n",
      "transformer.h.23.input_layernorm.bias torch.float32\n",
      "transformer.h.23.self_attention.query_key_value.weight torch.float32\n",
      "transformer.h.23.self_attention.query_key_value.bias torch.float32\n",
      "transformer.h.23.self_attention.dense.weight torch.float32\n",
      "transformer.h.23.self_attention.dense.bias torch.float32\n",
      "transformer.h.23.post_attention_layernorm.weight torch.float32\n",
      "transformer.h.23.post_attention_layernorm.bias torch.float32\n",
      "transformer.h.23.mlp.dense_h_to_4h.weight torch.float32\n",
      "transformer.h.23.mlp.dense_h_to_4h.bias torch.float32\n",
      "transformer.h.23.mlp.dense_4h_to_h.weight torch.float32\n",
      "transformer.h.23.mlp.dense_4h_to_h.bias torch.float32\n",
      "transformer.ln_f.weight torch.float32\n",
      "transformer.ln_f.bias torch.float32\n"
     ]
    }
   ],
   "source": [
    "for name, params in model.named_parameters():\n",
    "    print(name, params.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44e0ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import IA3Config, TaskType, get_peft_model\n",
    "\n",
    "config = IA3Config(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "657165a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f90cbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): IA3Model(\n",
       "    (model): BloomForCausalLM(\n",
       "      (transformer): BloomModel(\n",
       "        (word_embeddings): Embedding(46145, 2048)\n",
       "        (word_embeddings_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (h): ModuleList(\n",
       "          (0-23): 24 x BloomBlock(\n",
       "            (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (self_attention): BloomAttention(\n",
       "              (query_key_value): Linear(\n",
       "                (base_layer): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "                (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 6144x1])\n",
       "              )\n",
       "              (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): BloomMLP(\n",
       "              (dense_h_to_4h): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "              (gelu_impl): BloomGelu()\n",
       "              (dense_4h_to_h): Linear(\n",
       "                (base_layer): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "                (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 1x8192])\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (lm_head): Linear(in_features=2048, out_features=46145, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c66b3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 344,064 || all params: 1,303,455,744 || trainable%: 0.0264\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "441bcb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"../../caches/PEFT-lora\",\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    logging_steps=50,\n",
    "    num_train_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ddfeb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17521\\AppData\\Local\\Temp\\ipykernel_12072\\3918917228.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=tokenized_data,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce9707f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.17 GiB is allocated by PyTorch, and 426.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\trainer.py:2240\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2238\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2241\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\trainer.py:2555\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2548\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2549\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2551\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2553\u001b[0m )\n\u001b[0;32m   2554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2555\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2558\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2559\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2560\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2561\u001b[0m ):\n\u001b[0;32m   2562\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2563\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\trainer.py:3745\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3744\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3745\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3747\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   3748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3749\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3750\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3751\u001b[0m ):\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\trainer.py:3810\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3808\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[0;32m   3809\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[1;32m-> 3810\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3811\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\peft\\peft_model.py:1757\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[1;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[0;32m   1755\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1756\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[1;32m-> 1757\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1758\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1759\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1760\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1761\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1762\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1763\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1764\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1765\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1766\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1768\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[0;32m   1769\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1770\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\peft\\tuners\\tuners_utils.py:193\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[1;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\models\\bloom\\modeling_bloom.py:919\u001b[0m, in \u001b[0;36mBloomForCausalLM.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **deprecated_arguments)\u001b[0m\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeprecated_arguments\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    917\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 919\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    931\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    933\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\models\\bloom\\modeling_bloom.py:621\u001b[0m, in \u001b[0;36mBloomModel.forward\u001b[1;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **deprecated_arguments)\u001b[0m\n\u001b[0;32m    609\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    610\u001b[0m         block\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    611\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    618\u001b[0m         cache_position,\n\u001b[0;32m    619\u001b[0m     )\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m        \u001b[49m\u001b[43malibi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malibi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\models\\bloom\\modeling_bloom.py:432\u001b[0m, in \u001b[0;36mBloomBlock.forward\u001b[1;34m(self, hidden_states, alibi, attention_mask, layer_past, head_mask, use_cache, output_attentions, cache_position)\u001b[0m\n\u001b[0;32m    429\u001b[0m     residual \u001b[38;5;241m=\u001b[39m attention_output\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# MLP.\u001b[39;00m\n\u001b[1;32m--> 432\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayernorm_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n\u001b[0;32m    435\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (output,) \u001b[38;5;241m+\u001b[39m outputs\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\models\\bloom\\modeling_bloom.py:351\u001b[0m, in \u001b[0;36mBloomMLP.forward\u001b[1;34m(self, hidden_states, residual)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, residual: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 351\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgelu_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense_h_to_4h\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslow_but_exact:\n\u001b[0;32m    354\u001b[0m         intermediate_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(residual)\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\models\\bloom\\modeling_bloom.py:175\u001b[0m, in \u001b[0;36mBloomGelu.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m--> 175\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mGeLUFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m bloom_gelu_forward(x)\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\autograd\\function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m     )\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\models\\bloom\\modeling_bloom.py:152\u001b[0m, in \u001b[0;36mGeLUFunction.forward\u001b[1;34m(ctx, input)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    151\u001b[0m     ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbloom_gelu_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32me:\\software\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\transformers\\models\\bloom\\modeling_bloom.py:127\u001b[0m, in \u001b[0;36mbloom_gelu_forward\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbloom_gelu_forward\u001b[39m(x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    Custom bias GELU function. Adapted from Megatron-DeepSpeed code. Here we use a simple implementation (inference) to\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m    make the model jitable.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m            input hidden states\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(\u001b[38;5;241m0.79788456\u001b[39m \u001b[38;5;241m*\u001b[39m x \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241;43m0.044715\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m)))\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 4.00 GiB of which 0 bytes is free. Of the allocated memory 10.17 GiB is allocated by PyTorch, and 426.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b121d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()\n",
    "ipt = tokenizer(\"Human: {}\\n{}\".format(\"考试有哪些技巧？\", \"\").strip() + \"\\n\\nAssistant: \", return_tensors=\"pt\").to(model.device)\n",
    "tokenizer.decode(model.generate(**ipt, max_length=128, do_sample=True)[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61880c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
